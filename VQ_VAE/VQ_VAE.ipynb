{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d622a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as model\n",
    "import torchvision.utils as vutils\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e77ce2",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fac38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_workers = 0\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ff096",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef27104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transform\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b565b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transfrom,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=test_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cce8a9",
   "metadata": {},
   "source": [
    "## VQ-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7640adf",
   "metadata": {},
   "source": [
    "### Vector Quantizer Class  \n",
    "Disini kita akan mendefiniskan kelas dan operasi yang ada di bagian tengah dari VQ-VAE.  \n",
    "K = ukuran code book  \n",
    "Loss = $\\left\\| \\text{sg}[z_e(x)] - e \\right\\|_2^2 + \\beta \\left\\| z_e(x) - \\text{sg}[e] \\right\\|_2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "130a7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, code_book_size, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        '''\n",
    "        Args :\n",
    "            code_book_size : jumlah kode (vektor) yayng tersimpan di codebook -- ukuran kamus kuantisasi \n",
    "            embedding_dim : dimensi dari codebook -- ukuran vektor di codebook\n",
    "            commitment_cost : mengontrol seberapa keras encoder dipaksa agar outputnya dekat dengan codebook -- hyperparamater dari commitment loss\n",
    "        '''\n",
    "        self.code_book_size = code_book_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.commitment_cost = commitment_cost\n",
    "\n",
    "        # inisialisasi codebook\n",
    "        self.embedding = nn.Embedding(code_book_size, embedding_dim)            # ukuran dari codebook \n",
    "        # isi codebook dengan vektor acak dari distribusi uniform\n",
    "        self.embedding.weight.data.uniform_(-1.0 / code_book_size, 1.0 / code_book_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()                        # (batch_size, C, H, W) -> (batch_size, H, W, C)\n",
    "        input_shape = inputs.shape\n",
    "\n",
    "        # flatten -> ubah jadi 1D\n",
    "        flat_input = inputs.view(-1, 1, self.embedding_dim)                     # (batch_size * H * W, 1, C)\n",
    "\n",
    "        # hitung jarak antara setiap vektor input dengan setiap vektor di codebook\n",
    "        distances = (flat_input - self.embedding.weight.unsqueeze(0)).pow(2).mean(2)\n",
    "\n",
    "        # cari indeks dari vektor terdekat di codebook\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)          # (batch_size * H * W, 1)\n",
    "\n",
    "        # ambil vektor berdasrkan indeks\n",
    "        quantized = self.embedding(encoding_indices).view(input_shape)          # (batch_size, H, W, C)\n",
    "\n",
    "        # loss yang mengukur seberapa dekat input dengan vektor di codebook\n",
    "        loss_1 = F.mse_loss(quantized, inputs.detach())\n",
    "        loss_2 = self.commitment_cost * F.mse_loss(quantized.detach(), inputs)\n",
    "        loss = loss_1 + loss_2\n",
    "\n",
    "        # straight-through estimator ketika training\n",
    "        # mengalir langsung dari decoder ke encoder tidak mendapat upadate -- input tetap mendapat update gradien\n",
    "        if self.training:\n",
    "            quantized = inputs + (quantized - inputs).detach()\n",
    "\n",
    "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), encoding_indices.reshape(input_shape[0], -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985de8ce",
   "metadata": {},
   "source": [
    "### Residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf91dec",
   "metadata": {},
   "source": [
    "Supaya gradien mengalir lebih lama dan representasi belajar lebih dalam tanpa degradasi akibat “vanishing gradient”; skip-connection memungkinkan jaringan hanya mempelajari residual (perubahan kecil) sehingga training stabil dan lebih mudah mencapai akurasi tinggi. -- Kimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdd50148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        '''\n",
    "        Args :\n",
    "            channels : jumlah channel dari input\n",
    "            num_group : jumlah grup untuk normalisasi -- hyperparameter -- habis membagi batch_size\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        self.norm = nn.Sequential(\n",
    "            nn.GroupNorm(8, channels),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "\n",
    "            nn.GroupNorm(8, channels),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    # skip connection\n",
    "    def forward(self, x):\n",
    "        return x + self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b2751",
   "metadata": {},
   "source": [
    "### Up and Down Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f824da",
   "metadata": {},
   "source": [
    "- Downblock digunakan untuk mengekstrak fitur dan mengurangi dimensi spasial (downsampling)  \n",
    "- UpBlock digunakan untuk merekontruksi gambar  \n",
    "    - Pada UpBlock diogunakan UpSample untuk menaikkan ukuran gambar\n",
    "- Dua block ini akan digunakan di kelas Encoder dan Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0f7cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        '''\n",
    "        Args : \n",
    "            channels_in : jumlah channel dari input\n",
    "            channels_out : jumlah channel dari output\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # layer normalisasi\n",
    "        self.norm = nn.GroupNorm(8, channels_in)\n",
    "\n",
    "        # main path -- jalur utama pemrosesan\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_out, 3, stride=2, padding=1),\n",
    "            nn.GroupNorm(8, channels_out),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(channels_out, channels_out, 3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        # skip\n",
    "        self.skip = nn.Conv2d(channels_in, channels_out, 3, stride=2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)                        # dinormalisasi\n",
    "        x = F.elu(x, inplace=True)              # fungsi aktivasi ELU\n",
    "\n",
    "        return self.main(x) + self.skip(x)      # add elemtnr-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1133970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def _init__(self, channels_in, channels_out):\n",
    "        '''\n",
    "        Args :\n",
    "            channels_in : jumlah channel dari input\n",
    "            channels_out : jumlah channel dari output\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # layer normalisasi\n",
    "        self.norm = nn.GroupNorm(8, channels_in)\n",
    "\n",
    "        # UpSample layer\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # main path -- jalur utama pemrosesan\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(channels_in, channels_in, 3, stride=1, padding=1),\n",
    "            nn.GroupNorm(8, channels_in),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(channels_in, channels_out, 3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        # skip\n",
    "        self.skip = nn.Conv2d(channels_in, channels_out, 3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = F.elu(x, inplace=True)               # fungsi aktivasi ELU\n",
    "        x = self.up(x)                           # naikkan ukuran gambar\n",
    "        return self.main(x) + self.skip(x)       # add element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0067a",
   "metadata": {},
   "source": [
    "### Encoder dan Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42aae859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels, ch = 32, latent_channels = 32):\n",
    "        '''\n",
    "        Args : \n",
    "            channels : jumlah channel dari input\n",
    "            ch : jumlah channel dari output\n",
    "            latent_channels : jumlah channel dari latent space\n",
    "        '''\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(channels, ch, 3, stride=1, padding=1)               # input \n",
    "\n",
    "        # Downsampling\n",
    "        self.conv_block_1 = DownBlock(ch, ch * 2)\n",
    "        self.conv_block_2 = DownBlock(ch * 2, ch * 4)\n",
    "\n",
    "        # Residual blocks -- memiliki parameter yang sama untuk mempertahankan bentuk dimensi\n",
    "        self.res_block_1 = ResBlock(ch * 4)\n",
    "        self.res_block_2 = ResBlock(ch * 4)\n",
    "        self.res_block_3 = ResBlock(ch * 4)\n",
    "\n",
    "        # out layer -> mengubah dimensi ke latent space\n",
    "        self.conv_out = nn.Conv2d(ch * 4, latent_channels, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)                        # (batch_size, channels, H, W) -> (batch_size, ch, H, W)\n",
    "        \n",
    "        x = self.conv_block_1(x)                  # DownBlock 1\n",
    "        x = self.conv_block_2(x)                  # DownBlock 2\n",
    "\n",
    "        x = self.res_block_1(x)                   # ResBlock 1\n",
    "        x = self.res_block_2(x)                   # ResBlock 2\n",
    "        x = F.elu(self.res_block_3(x))            # ResBlock 3\n",
    "\n",
    "        return self.conv_out(x)                    # output ke latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f10ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels, ch = 32, latent_channels = 32):\n",
    "        '''\n",
    "        Args : \n",
    "            channels : jumlah channel dari input\n",
    "            ch : jumlah channel dari output\n",
    "            latent_channels : jumlah channel dari latent space\n",
    "        '''\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(latent_channels, ch * 4, 3, stride=1, padding=1)    # input dari latent space\n",
    "\n",
    "        # Upsampling\n",
    "        self.conv_block_1 = UpBlock(ch * 4, ch * 2)\n",
    "        self.conv_block_2 = UpBlock(ch * 2, ch)\n",
    "\n",
    "        # Residual blocks\n",
    "        self.res_block_1 = ResBlock(ch * 4)\n",
    "        self.res_block_2 = ResBlock(ch * 4)\n",
    "        self.res_block_3 = ResBlock(ch * 4)\n",
    "\n",
    "        # out layer -> rekonstruksi ke gambar asli\n",
    "        self.conv_out = nn.Conv2d(ch, channels, 3, stride=1, padding=1)               # output ke jumlah channel input\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "\n",
    "        x = self.res_block_1(x)\n",
    "        x = self.res_block_2(x)\n",
    "        x = self.res_block_3(x)\n",
    "\n",
    "        x = self.conv_block_1(x)                  # UpBlock 1\n",
    "        x = self.conv_block_2(x)                  # UpBlock 2\n",
    "\n",
    "        return torch.tanh(self.conv_out(x))       # rekonstruksi ke gambar asli dengan fungsi aktivasi tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf05d6a",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1500102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, channel_in, ch = 16, latent_channels = 32, code_book_size = 64, commitment_cost = 0.25):\n",
    "        super(VQVAE, self).__init__()\n",
    "\n",
    "        # sisi kiri -- encoder\n",
    "        self.encoder = Encoder(channels=channel_in, ch=ch, latent_channels=latent_channels)\n",
    "\n",
    "        # tengah -- Vector Quantizer -- latent space\n",
    "        self.vq = VectorQuantizer(code_book_size=code_book_size, embedding_dim=latent_channels, commitment_cost=commitment_cost)\\\n",
    "        \n",
    "        # sisi kanan -- decoder\n",
    "        self.decoder = Decoder( channels=channel_in, ch=ch, latent_channels=latent_channels)\n",
    "\n",
    "    def encode(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        vq_loss, quantized, encoding_indices = self.vq(encoded)\n",
    "        return vq_loss, quantized, encoding_indices\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        vq_loss, quantized, encoding_indices = self.encode(x)\n",
    "        recon = self.decode(quantized)\n",
    "\n",
    "        return recon, vq_loss, encoding_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f6199",
   "metadata": {},
   "source": [
    "### Create network and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c610186",
   "metadata": {},
   "source": [
    "scaler menggunakan `torch.amp.GradScaler` -> membantu training model dengan mixed precision (presisi campuran) pada GPU NVIDIA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc3e385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some config\n",
    "code_book_size = 32\n",
    "latent_channels = 10\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d48cec4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# network\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vae_net \u001b[38;5;241m=\u001b[39m VQVAE(channel_in\u001b[38;5;241m=\u001b[39m\u001b[43mtra\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tra' is not defined"
     ]
    }
   ],
   "source": [
    "# network\n",
    "vae_net = VQVAE(channel_in=tra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
